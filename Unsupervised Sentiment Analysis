import pandas as pd
import nltk
from nltk.corpus import sentiwordnet as swn
from bs4 import BeautifulSoup
import unicodedata as ud

data=pd.read_csv(r'C:\Users\Rajath\Desktop\Praxis\Term 3\Text mining class mathangi\Review.csv',nrows=1000,header=None)

data.columns=['Review']

for i in range(0, 1000):
    text=data['Review'][i]
    #html parsing
    soup=BeautifulSoup(text,'lxml')
    text=soup.get_text()
    #removing accent
    text=ud.normalize('NFKD',text).encode('ascii','ignore').decode("utf-8")
    data['Review'][i] = text

length=list()
for review in data['Review']:
    words=review.split(' ')
    w_length=len(words)
    length.append(w_length)

data['Length']=length

data['Service']=0
for i in range(0,1000):
    if ('Amazon' in data['Review'][i]) or ('amazon' in data['Review'][i]) or data['Length'][i]<=15 :
        data['Service'][i]=1
    else:
        data['Service'][i]=0

text_tokens=[]
tagged_text=[]
for i in range(0,1000):
    text=data['Review'][i]
    text_tokens.append(nltk.word_tokenize(text))
    tagged_text.append(nltk.pos_tag(text_tokens[i]))

phrases=[]
count=[0]*1000
for i in range(0,1000):
    i_list=tagged_text[i]
    for j in range(0,(len(i_list)-2)):
        if(i_list[j][1]=='JJ'):
            if(i_list[j+1][1]=='NN' or i_list[j+1][1]=='NNS'):
                i_list.append([i_list[j],i_list[j+1]])
                count[i]=count[i]+1
        elif(i_list[j][1]=='RB' or i_list[j][1]=='RBR' or i_list[j][1]=='RBS'):
            if(i_list[j+1][1]=='JJ' and (i_list[j+2][1]!='NN' or i_list[j+2][1]!='NNS')):
                i_list.append([i_list[j],i_list[j+1]])
                count[i]=count[i]+1
        elif(i_list[j][1]=='JJ' and i_list[j+1][1]=='JJ'):
            if(i_list[j+2][1]!='NN' or i_list[j+2][1]!='NNS'):
                i_list.append([i_list[j],i_list[j+1]])
                count[i]=count[i]+1
        elif((i_list[j][1]=='NN' or i_list[j][1]=='NNS') and i_list[j+1][1]=='JJ'):
            if(i_list[j+2][1]!='NN' or i_list[j+2][1]!='NNS'):
                i_list.append([i_list[j],i_list[j+1]])
                count[i]=count[i]+1
        elif((i_list[j][1]=='RB' or i_list[j][1]=='RBR' or i_list[j][1]=='RBS')):
            if(i_list[j+1][1]=='VB' or i_list[j+1][1]=='VBD' or i_list[j+1][1]=='VBN' or i_list[j+1][1]=='VBG'):
                i_list.append([i_list[j],i_list[j+1]])
                count[i]=count[i]+1
                
final=[]
i=0
for i_list in tagged_text:
    if(count[i]>0):
        k=count[i]
        final.append(i_list[-k:])
    else:
        final.append(None)
    i=i+1 
    

data['PositiveScore']=0
data['NegativeScore']=0
data['ObjectiveScore']=0
data['FinalScore']=0
data['FinalSentiment']=''

last=[]
for i in range(0,1000):
    i_list=final[i]
    if i_list!=None:
        last.append(i_list)
    else:
        last.append([('A','RB'),('A','JJ')])


for i_list in last:
    pos_score = neg_score = token_count = obj_score = 0
    try:
        for si_list in i_list:
            for word, tag in si_list:
                ss_set = None
                if ('NN' in tag or 'NNS' in tag) and list(swn.senti_synsets(word, 'n')):
                    ss_set = list(swn.senti_synsets(word, 'n'))[0]
                elif 'VB' in tag and list(swn.senti_synsets(word, 'v')):
                    ss_set = list(swn.senti_synsets(word, 'v'))[0]
                elif 'JJ' in tag and list(swn.senti_synsets(word, 'a')):
                    ss_set = list(swn.senti_synsets(word, 'a'))[0]
                elif ('RB' in tag or 'RBS' in tag) and list(swn.senti_synsets(word, 'r')):
                    ss_set = list(swn.senti_synsets(word, 'r'))[0]
                if ss_set:
                    # add scores for all found synsets
                    pos_score += ss_set._pos_score
                    neg_score += ss_set._neg_score
                    obj_score += ss_set._obj_score
                    token_count += 1
            final_score = pos_score - neg_score
            norm_final_score = round(float(final_score) / token_count, 2)
            final_sentiment = 'positive' if norm_final_score >= 0 else 'negative'
            data['PositiveScore'][i]=pos_score
            data['NegativeScore'][i]=neg_score
            data['ObjectiveScore'][i]=obj_score
            data['FinalScore']= norm_final_score
            data['FinalSentiment']=final_sentiment
            print(final_sentiment)
    except:
        print('Error')
        pass
